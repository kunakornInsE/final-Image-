{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling_image(image, reduction_scale) : # Reduce image resolution Pyr lelel\n",
    "    for i in range(0, reduction_scale) :\n",
    "        if len(image.shape) > 2:\n",
    "            row, col = image.shape[:2]\n",
    "        else :\n",
    "            row, col = image.shape\n",
    "        \n",
    "        image = cv2.pyrDown(image,dstsize=(col//2,row//2))\n",
    "    return imag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_text(img, pose, dy, text) :\n",
    "    x0 = pose[0]\n",
    "    y0 = pose[1]\n",
    "    for i, line in enumerate(text.split('\\n')) :\n",
    "        y = y0 + i*dy\n",
    "        cv2.putText(img, line, np.int32([x0, y]), cv2.FONT_HERSHEY_COMPLEX, 0.75, (50,200,255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()\n",
    "bf = cv2.BFMatcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_object_detection(template_img, template_gray, query_img, query_gray, min_match_number) :\n",
    "    template_kpts, template_desc = sift.detectAndCompute(template_gray, None)\n",
    "    query_kpts, query_desc = sift.detectAndCompute(query_gray, None)\n",
    "    matches = bf.knnMatch(template_desc, query_desc, k=2)\n",
    "    good_matches = list()\n",
    "    good_matches_list = list()\n",
    "    for m, n in matches :\n",
    "        if m.distance < 0.65*n.distance : #\n",
    "            good_matches.append(m)\n",
    "            good_matches_list.append([m])\n",
    "    \n",
    "    if len(good_matches) > min_match_number :\n",
    "        src_pts = np.float32([ template_kpts[m.queryIdx].pt for m in good_matches ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ query_kpts[m.trainIdx].pt for m in good_matches ]).reshape(-1,1,2)\n",
    "\n",
    "        H, inlier_masks = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 10.5) # H RANSAC \n",
    "        # get the bounding box around template image\n",
    "        h, w = template_img.shape[:2]\n",
    "        template_box = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1,1,2)\n",
    "        transformed_box = cv2.perspectiveTransform(template_box, H)\n",
    "\n",
    "        detected_img = cv2.polylines(query_img, [np.int32(transformed_box)], True, (100,100,200), 5, cv2.LINE_AA)# ความหนาเส้น สี\n",
    "        drawmatch_img = cv2.drawMatchesKnn(template_img, template_kpts, detected_img, query_kpts, good_matches_list, None, flags=2, matchesMask=inlier_masks)\n",
    "\n",
    "        return detected_img, drawmatch_img\n",
    "    else :\n",
    "        print('Keypoints not enough')\n",
    "        return query_img,query_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n"
     ]
    }
   ],
   "source": [
    "vid = cv2.VideoCapture('test/videos/final_exam/Dataset-1/right_output-1.avi')\n",
    "\n",
    "# เปิดภาพ\n",
    "template_img = cv2.imread('images/final_exam/Templates/Template-2.png')\n",
    "# ทำรูปขาวดำ\n",
    "template_gray =  cv2.cvtColor(template_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while vid.isOpened() :\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    if ret :\n",
    "        #แปลงวิดีโอให้เป็นขาวดำ\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "        #จำนวนการจับคู่ ห้ามน้อยกว่า 10\n",
    "        detected, drawmatch =  feature_object_detection(template_img, template_gray, frame, frame_gray, 12)\n",
    "\n",
    "        cv2.imshow('Video frame', detected)\n",
    "\n",
    "        if cv2.waitKey(int(1000/1000)) & 0xFF == ord('q') : # this line control the period between image frame \n",
    "            break\n",
    "    else :\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5da3b4ecafdda919b777fa8121f7f4038238cda8800e15ccc91279d0572daac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit (system)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
