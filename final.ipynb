{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()\n",
    "bf = cv2.BFMatcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_object_detection(template_img, template_gray, query_img, query_gray, min_match_number) :\n",
    "    template_kpts, template_desc = sift.detectAndCompute(template_gray, None)\n",
    "    query_kpts, query_desc = sift.detectAndCompute(query_gray, None)\n",
    "    matches = bf.knnMatch(template_desc, query_desc, k=2)\n",
    "    good_matches = list()\n",
    "    good_matches_list = list()\n",
    "    for m, n in matches :\n",
    "        if m.distance < 0.65*n.distance : #\n",
    "            good_matches.append(m)\n",
    "            good_matches_list.append([m])\n",
    "    \n",
    "    if len(good_matches) > min_match_number :\n",
    "        src_pts = np.float32([ template_kpts[m.queryIdx].pt for m in good_matches ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ query_kpts[m.trainIdx].pt for m in good_matches ]).reshape(-1,1,2)\n",
    "\n",
    "        H, inlier_masks = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 10.5) # H RANSAC \n",
    "        # get the bounding box around template image\n",
    "        h, w = template_img.shape[:2]\n",
    "        template_box = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1,1,2)\n",
    "        transformed_box = cv2.perspectiveTransform(template_box, H)\n",
    "\n",
    "        detected_img = cv2.polylines(query_img, [np.int32(transformed_box)], True, (100,100,200), 5, cv2.LINE_AA)# ความหนาเส้น สี\n",
    "        drawmatch_img = cv2.drawMatchesKnn(template_img, template_kpts, detected_img, query_kpts, good_matches_list, None, flags=2, matchesMask=inlier_masks)\n",
    "\n",
    "        return detected_img, drawmatch_img\n",
    "    else :\n",
    "        print('Keypoints not enough')\n",
    "        return query_img,query_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n",
      "Keypoints not enough\n"
     ]
    }
   ],
   "source": [
    "vid = cv2.VideoCapture('test/videos/final_exam/Dataset-1/right_output-1.avi')\n",
    "\n",
    "# เปิดภาพ\n",
    "template_img = cv2.imread('images/final_exam/Templates/Template-2.png')\n",
    "# ทำรูปขาวดำ\n",
    "template_gray =  cv2.cvtColor(template_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while vid.isOpened() :\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    if ret :\n",
    "        #แปลงวิดีโอให้เป็นขาวดำ\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "        #จำนวนการจับคู่ ห้ามน้อยกว่า 10\n",
    "        detected, drawmatch =  feature_object_detection(template_img, template_gray, frame, frame_gray, 12)\n",
    "\n",
    "        cv2.imshow('Video frame', detected)\n",
    "\n",
    "        if cv2.waitKey(int(1000/1000)) & 0xFF == ord('q') : # this line control the period between image frame \n",
    "            break\n",
    "    else :\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5da3b4ecafdda919b777fa8121f7f4038238cda8800e15ccc91279d0572daac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit (system)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
